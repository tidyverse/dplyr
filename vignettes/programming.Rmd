---
title: "Programming with dplyr"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Programming with dplyr}
  %\VignetteEngine{knitr::rmarkdown}
  %\usepackage[utf8]{inputenc}
---

```{r setup, echo = FALSE, message = FALSE}
knitr::opts_chunk$set(collapse = T, comment = "#>")
options(tibble.print_min = 4L, tibble.print_max = 4L)
library(dplyr)

quo <- rlang::quo
quos <- rlang::quos
enquo <- rlang::enquo
quo_name <- rlang::quo_name
```

Most dplyr functions use non-standard evaluation (NSE). This is a catch-all term that means they don't follow the usual R rules of evaluation. Instead, they capture the expression that you typed and evaluate it in a custom way. This has two main benefits for dplyr code:

*   Operations on data frames can be expressed succinctly because
    in expressions you don't need to repeat the name of the data frame;
    i.e. `filter(df, x == 1, y == 2, z == 3)` vs. 
    `df[df$x == 1 & df$y ==2 & df$z == 3, ]`.
    
*   dplyr can choose to compute results in a different way to base R.
    This is important for database backends because dplyr itself doesn't
    do any work, but instead generates the SQL that tells the database
    what to do.

Unfortunately these benefits do not come for free. There are two main drawbacks:

*   Most dplyr arguments are not __referentially transparent__. That means
    you can't replace a value with a seemingly equivalent object, that you've defined elsewhere. In other words, this code:
    
    ```{r, eval = FALSE}
    filter(df, my_var == 1)
    ```
    
    Is not equivalent to this code:
    
    ```{r, eval = FALSE}
    var <- my_var
    filter(df, var == 1)
    ```
    
    nor to this code:
    
    ```{r, eval = FALSE}
    var <- "my_var"
    filter(df, var == 1)
    ```
    
    This makes it harder for users to create functions that use their own inputs to pass input into dplyr functions.
    
    *Jenny: I still think `var <- "my_var"; filter(df, var == 1)` is a better example, so I added it. I think it's too obvious that `var <- my_var` can't possibly do the right thing. But it doesn't take too much magical thinking to kindle hope that my example works, especially once you're in a function context. One last concern: do we worry some people will get distracted by re: concern about masking `var()`?*
    
*   dplyr code is ambiguous. Depending on what variables are defined where, 
    `filter(df, x == y)` could be equivalent to any of:

    ```{r, eval = FALSE}
    df[df$x == df$y, ]
    df[df$x == y, ]
    df[x == df$y, ]
    df[x == y, ]
    ```
    
    This is useful when working interactively (because it saves typing and you
    quickly spot problems) but makes functions more unpredictable than you 
    might desire.

Fortunately, dplyr provides tools to overcome these challenges. They require a little more typing, but a small amount of upfront work is worth it because they help you save time in the long run.

This vignette has two goals:

*   Show you how to use dplyr's __pronouns__ and __quasiquotation__
    to write reliable functions that reduce duplication in your data analysis 
    code.
    
*   Teach you about __quosures__ and the underyling theory of __tidyeval__.

*Jenny: What is tidyeval? A function? A package? A way of life? :-)*

We'll start with some practical tools and then dive into the deeper theory.

## Programming recipes

The following recipes walk you through the basics of tidyeval, with the nominal goal of reducing duplication in dplyr code. The examples here are somewhat inauthentic because we've reduced them down to very simple components to make them easier to understand. They're so simple that you might wonder why we bother writing a function at all. But it's a good idea to learn the ideas on simple examples, so that you're better prepared to apply them to the more complex situations you'll see in your own code.

### Different data sets

You already know how to write functions that vary over referentially transparent arguments like `.data`, the first and primary argument for dplyr's core functions.

*Jenny: Feels like "vary over" can be improved upon, but I get it. I'll try to propose better wording for this concept: plumbing up stuff you compute in your function, probably using your inputs, to arguments of dplyr functions.*

```{r, eval = FALSE}
mutate(df1, y = a + x)
mutate(df2, y = a + x)
mutate(df3, y = a + x)
mutate(df4, y = a + x)
```

```{r}
mutate_y <- function(df) {
  mutate(df, y = a + x)
}
```

However, there's a major drawback to this simple approach: it can fail silently if one of the variables isn't present in the data frame, but is present in the global environment. 

```{r}
df1 <- tibble(x = 1:3)
a <- 10
mutate_y(df1)
```

We can fix that ambiguity by being more explicit and using the `.data` pronoun. This will (should) throw an error if the variable doesn't exist:

```{r, error = TRUE}
mutate_y <- function(df) {
  mutate(df, y = .data$a + .data$x)
}

mutate_y(df1)
```

*Jenny: Sidebar: could that error message be improved? E.g., "No object `a` exists in `.data`."*

If this function is in a package, using `.data` also prevents `R CMD check` from giving a NOTE about undefined global variables (provided that you've also imported `rlang::.data` with `@importFrom rlang .data`).

### Different expressions

Working with the other arguments is more challenging because they are not referentially transparent. Let's start with a simple case: you want to vary the grouping variable for a data summarization.

```{r}
df <- tibble(
  g1 = c(1, 1, 2, 2, 2),
  g2 = c(1, 2, 1, 2, 1),
  a = sample(5), 
  b = sample(5)
)

df %>%
  group_by(g1) %>%
  summarise(a = mean(a))

df %>%
  group_by(g2) %>%
  summarise(a = mean(a))
```

You might hope that this will work:

```{r, error = TRUE}
my_summarise <- function(df, group_var) {
  df %>%
    group_by(group_var) %>%
    summarise(a = mean(a))
}

my_summarise(df, g1)
```

But it does not. You might hope that providing the variable name as a string will fix things:

```{r, error = TRUE}
my_summarise(df, "g2")
```

But it does not.

Instead we need to capture, or __quote__, the specification of the group variable as an __expression__. There are two ways to do this in base R: use `quote()` to create an expression or use the tilde operator `~` to create a formula.

```{r}
quote(g1)
~g1
```

For various reasons, neither of these does quite what we want, so instead we'll use `quo()` (this comes from the rlang package but is also exported by dplyr).

*Jenny: This is where you'll briefly explain the difference and the problem, (instead of "for various reasons ...").*

```{r}
var <- quo(g1)
var
```

This creates a __quosure__, which is a special type of formula (more details later).

Now that we've captured this expression, how do we use it with `group_by()` inside our function? We can't just shove this into our naive approach, because `group_by()` expects its arguments to be names of existing variables:

```{r, error = TRUE}
var <- quo(g1)
my_summarise(df, var)
```

*Jenny: the connection to "`group_by()` automatically quotes its inputs" is not obvious to me. The need to unquote the expression and actually evaluate it is more clear. Feels like a discussion of controlling when something gets evaluated could be helpful.*

In other words, `group_by()` automatically quotes its inputs. But `var` is already quoted, so we need some way to __unquote__ it. In the tidyeval framework, you unquote an expression by putting `!!` in front of it.

*Jenny: I wanted to "just" unquote `var` but `!!var` does not work as top-level code. Is there anything to be said about that here?*

```{r}
df %>%
  group_by(!!var) %>%
  summarise(a = mean(a))
```

We are now almost able to fix our function:

```{r, error = TRUE}
my_summarise <- function(df, group_by) {
  group_by <- quo(group_by)
  print(group_by)
  
  df %>%
    group_by(!!group_by) %>%
    summarise(a = mean(a))
}

my_summarise(df, g1)
my_summarise(df, g2)
```

I've added a `print()` call to make it obvious what's going wrong here: `quo(group_by)` always returns `~group_by`. It is being too literal! We want it to substitute the value that the user supplied, i.e. to return `~g1`, so we need a new function: `enquo()`. `enquo()` is an unquoting function specialized to the current application: usage inside functions.

*Jenny: I edited some based on discussion, but probably don't have it quite right.*

```{r}
my_summarise <- function(df, group_by) {
  group_by <- enquo(group_by)
  print(group_by)

  df %>%
    group_by(!!group_by) %>%
    summarise(a = mean(a))
}

my_summarise(df, g1)
```

(If you're familiar with `quote()` and `substitute()` in base R, `quo()` is equivalent to `quote()` and `enquo()` is equivalent to `substitute()`.)

You might wonder how to extend this to handle multiple grouping variables: we'll come back to that a little later.

*Jenny: I'm still left a bit unsatisfied re: the need to switch from `quo()` to `enquo()`. We talked about the need for more words. Why did we build uo `quo()` then switch to `enquo()` at the last moment? What's the difference? Basically translate this idea into English (taken from help to `substitute()`): If it is a promise object, i.e., a formal argument to a function or explicitly created using delayedAssign(), the expression slot of the promise replaces the symbol.*

### Different input variable

Now let's tackle something a bit more complicated. The code below shows a duplicate `summarise()` statement where we compute three summaries, varying the input variable.

```{r}
summarise(df, mean = mean(a), sum = sum(a), n = n())
summarise(df, mean = mean(a * b), sum = sum(a * b), n = n())
```

To turn this into a function, we start in the same way: by quoting the variable with `quo()`, then unquoting it in the dplyr call with `!!`.

```{r}
var <- quo(a)
summarise(df, mean = mean(!!var), sum = sum(!!var), n = n())
```

You can also wrap `quo()` around the dplyr call to see what the generated call will look like.

```{r}
quo(summarise(df, 
  mean = mean(!!var),
  sum = sum(!!var),
  n = n()
))
```

This is the reason we use `quo()` instead of `~`: `quo()` also does unquoting. This makes it useful for previewing the expression the dplyr will execute.

Now we can turn our code into a function (remembering to replace `quo()` with `enquo()`), and check that it works:

```{r}
my_summarise2 <- function(df, expr) {
  expr <- enquo(expr)
  
  summarise(df, 
    mean = mean(!!expr),
    sum = sum(!!expr),
    n = n()
  )
}
my_summarise2(df, a)
my_summarise2(df, a * b)
```

### Different input and output variable

The next challenge is to vary the name of the output variables:

```{r}
mutate(df, mean_a = mean(a), sum_a = sum(a))
mutate(df, mean_b = mean(b), sum_b = sum(b))
```

This code is similar to the previous example, but there are two new wrinkles:

* We create the new names by pasting together strings, so
  we need `quo_name()` to convert the input expression to a string.

* `!!mean_name = mean(!!expr)` isn't valid R code, so we need to
  use the `:=` helper provided by rlang.

```{r}
my_mutate <- function(df, expr) {
  expr <- enquo(expr)
  mean_name <- paste0("mean_", quo_name(expr))
  sum_name <- paste0("sum_", quo_name(expr))
  
  mutate(df, 
    !!mean_name := mean(!!expr), 
    !!sum_name := sum(!!expr)
  )
}

my_mutate(df, a)
```

### Capturing multiple variables

It would be nice to extend `my_summarise()` to accept any number of grouping variables. We need to make three changes:

*   Use `...` in the function definition so our function can accept any number
    of arguments.
    
*   Use `quos()` to capture all the `...` as a list of formulas.

*   Use `!!!` instead of `!!` to __splice__ the arguments into `group_by()`.

```{r}
my_summarise <- function(df, ...) {
  group_by <- quos(...)

  df %>%
    group_by(!!!group_by) %>%
    summarise(a = mean(a))
}

my_summarise(df, g1, g2)
```

`!!!` takes a list of elements and splices them into to the current call. Look at the bottom of the `!!!` and think `...`.

```{r}
args <- list(na.rm = TRUE, trim = 0.25)
quo(mean(x, !!! args))

args <- list(quo(x), na.rm = TRUE, trim = 0.25)
quo(mean(!!! args))
```

Now that you've learned the basics of tidyeval through some practical examples, we'll dive into the theory. This will help you generalise what you've learned here to new situations.

## Quoting

Quoting is the action of capturing an expression instead of evaluating it. All expression-based functions quote their arguments and get the R code as an expression rather than the result of evaluating that code. If you are an R user, you probably quote expressions on a regular basis. One of the most important quoting operators in R is the
_formula_. It is famously used for the specification of statistical models:

```{r}
disp ~ cyl + drat
```

The other quoting operator in base R is `quote()`. It returns a raw
expression rather than a formula:

```{r}
# Computing the value of the expression:
toupper(letters[1:5])

# Capturing the expression:
quote(toupper(letters[1:5]))
```

(Note that despite being called the double quote, `"` is not a quoting operator, because it generates a string, not an expression.)

In practice, the formula is the better of the two options because captures both the code, and its execution __environment__. This important because even simple expression can yield different values in different environments. For example, the `x` in the following two expressions refers to different values:

```{r}
f <- function(x) {
  ~ x
}

x1 <- f(10)
x2 <- f(100)
```

It might look like the expressions are the same if you print them out. But look carefully at the environments --- they're different.

```{r}
x1
x2
```

When we evaluate those formulas using `rlang::eval_tidy()`, we see that they yield different values:

```{r, message = FALSE}
library(rlang)

eval_tidy(x1)
eval_tidy(x2)
```

This is an important property of R: one name can refer to different values in different environments.

When an object keep tracks of an environment, it is said to have an enclosure. This is the reason that functions in R are sometimes referred to as closures:

```{r}
typeof(mean)
```

For this reason we use a special name to refer to one-sided formulas: __quosures__. One-sided formulas are quotes (they carry an expression) that bundle their environment. 

Quosures are regular R objects. They can be stored in a variable and inspected:

```{r}
var <- ~toupper(letters[1:5])
var

# You can extract its expression:
f_rhs(var)

# Or inspect its enclosure:
f_env(var)
```

The tidyeval framework is characterised by its use of quosures. Using `enquo()` to capture a quosure is safer than the base R equivalent of using `substitute()` to capture only the expression. This enables dplyr to compute expressions that refer to a mixture of data frame columns and user-defined variables:

```{r}
user_var <- 1000
mtcars %>% summarise(cyl = mean(cyl) * user_var)
```

Automatic quoting makes dplyr very convenient for interactive use. But if you want to program with dplyr, you need some way to refer to variables indirectly. The solution to this problem is __quasiquotation__, which allows you to evaluate directly inside an expression that is otherwise quoted. 

## Quasiquotation

> Put simply, quasi-quotation enables one to introduce symbols that stand for 
> a linguistic expression in a given instance and are used as that linguistic 
> expression in a different instance.
--- [Willard van Orman Quine](https://en.wikipedia.org/wiki/Quasi-quotation)

Quasiquotation was coined by Willard van Orman Quine in the 1940s, and was adopted for programming by the LISP community in the 1970s. All expression-based functions in the tidyeval framework support quasiquotation. Unquoting cancels quotation of parts of an expression. There are three types of unquoting:

* basic
* unquote splicing
* unquoting names

### Unquoting

The first important operation is the basic unquote, which comes in a functional form, `UQ()`, and as syntactic-sugar, `!!`.

```{r}
# Here we capture `letters[1:5]` as an expression:
quo(toupper(letters[1:5]))

# Here we capture the value of `letters[1:5]`
quo(toupper(!!letters[1:5]))
quo(toupper(UQ(letters[1:5])))
```

It is also possible to unquote other quoted expressions. Unquoting such
symbolic objects provides a powerful a way of manipulating expressions. 

```{r}
var1 <- quo(letters[1:5])
quo(toupper(!!var1))
```

You can safely unquote quosures because they track their environments, and tidyeval functions know how to evaluate them. This allows any depth of quoting and unquoting.

```{r}
my_mutate <- function(x) {
  mtcars %>%
    select(cyl) %>%
    slice(1:4) %>%
    mutate(cyl2 = cyl + (!! x))
}

f <- function(x) quo(x)
expr1 <- f(100)
expr2 <- f(10)

my_mutate(expr1)
my_mutate(expr2)
```

### Unquote-splicing

The second unquote operation is unquote-splicing. Its functional  form is `UQS()` and the syntactic shortcut is `!!!`. It takes a vector and inserts each element of the vector becomes an argument in the surrounding function call:

```{r}
quo(list(!!! letters[1:5]))
```

A very useful feature of unquote-splicing is that the vector names
become argument names:

```{r}
x <- list(foo = 1L, bar = quote(baz))
quo(list(!!! x))
```

This makes it easy to program with dplyr verbs that take named dots:

```{r}
args <- list(mean = ~mean(cyl), count = ~n())
mtcars %>%
  group_by(am) %>%
  summarise(!!! args)
```

### Setting variable names

The final unquote operation is setting argument names. You've seen one way to do that above, but you can also use the definition operator `:=` instead of `=`. `:=` supports  supports unquoting on both the LHS and the RHS. 

The rules on the LHS are slightly different: the unquoted operand should evaluate to a string or a symbol.

```{r}
mean_nm <- "mean"
count_nm <- "count"

mtcars %>%
  group_by(am) %>%
  summarise(
    !!mean_nm := mean(cyl),
    !!count_nm := n()
  )
```
