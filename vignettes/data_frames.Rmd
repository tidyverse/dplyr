---
title: "Data frames"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Data frames}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r, echo = FALSE, message = FALSE}
knitr::opts_chunk$set(collapse = T, comment = "#>")
options(dplyr.print_min = 4L, dplyr.print_max = 4L)
library(dplyr)
```

## Creating

`data_frame()` is a nice way to create data frames. It encapsulates best practices for data frames:

  * It never changes the type of its inputs (i.e. no more `stringsAsFactors = FALSE`!)
    
    ```{r}
    data.frame(x = letters) %>% sapply(class)
    data_frame(x = letters) %>% sapply(class)
    ```
    
    This makes it easier to use with list-columns:
    
    ```{r}
    data_frame(x = 1:3, y = list(1:5, 1:10, 1:20))
    ```
    
    List-columns are most commonly created by `do()`, but they can be useful to
    create by hand.
      
  * It never adjusts the names of variables:
  
    ```{r}
    data.frame(`crazy name` = 1) %>% names()
    data_frame(`crazy name` = 1) %>% names()
    ```

  * It evaluates its arguments lazyily and in order:
  
    ```{r}
    data_frame(x = 1:5, y = x ^ 2)
    ```

  * It adds `tbl_df()` class to output so that if you accidentaly print a large 
    data frames you only get the first few rows.
    
    ```{r}
    data_frame(x = 1:5) %>% class()
    ```

  * It changes the subsetting behaviour to make the use of `[` consistent.
    For a `tbl_df()` object, subsetting by `[` will always return a `tbl_df()`
    object; whereas subsetting by `[[` will always return its (subsetted) 
    contents.
    
    The user should be aware of one subsetting case where a `tbl_df()` object  
    will produce a different result than a `data.frame()` object:
  
    ```{r}
    df <- data.frame(a = 1:2, b = 1:2)
    str(df[, "a"])
    
    tbldf <- tbl_df(df)
    str(tbldf[, "a"])
    ```
    
  * It never uses `row.names()`, because the whole point of tidy data is to 
    store variables in a consistent way, so we shouldn't put one variable in a 
    special attribute.
  
  * It only recycles vectors of length 1. Recycling vectors of other lengths 
    is a frequent source of bugs.

## Coercion

To complement `data_frame()`, dplyr provides `as_data_frame()` for coercing lists into data frames. It does two things:

* Checks that the input list is valid for a data frame, i.e. that each element
  is named, is a 1d atomic vector or list, and all elements have the same 
  length.
  
* Sets the class and attributes of the list to make it behave like a data frame.
  This modification does not require a deep copy of the input list, so is
  very fast.
  
This is much simpler than `as.data.frame()`. It's hard to explain precisely what `as.data.frame()` does, but it's similar to `do.call(cbind, lapply(x, data.frame))` - i.e. it coerces each component to a data frame and then `cbinds()` them all together. Consequently `as_data_frame()` is much faster than `as.data.frame()`:

```{r}
l2 <- replicate(26, sample(100), simplify = FALSE)
names(l2) <- letters
microbenchmark::microbenchmark(
  as_data_frame(l2),
  as.data.frame(l2)
)
```

The speed of `as.data.frame()` is not usually a bottleneck in interactive use, but can be a problem when combining thousands of messy inputs into one tidy data frame.

## Memory

One of the reasons that dplyr is fast is that it is very careful about when it makes copies of columns. This section describes how this works, and gives you some useful tools for understanding the memory usage of data frames in R.

The first tool we'll use is `dplyr::location()`. It tells us three things about a data frame:

* where the object itself is located in memory
* where each column is located
* where each attribute is located

```{r}
location(iris)
```

It's useful to know the memory address, because if the address changes, then you know R has made a copy. Copies are bad because it takes time to copy a vector. This isn't usually a bottleneck if you have a few thousand values, but if you have millions or tens of millions it starts to take up a significant amount of time. Unnecessary copies are also bad because they take up memory.

R tries to avoid making copies where possible. For example, if you just assign `iris` to another variable, it continues to the point same location:

```{r}
iris2 <- iris
location(iris2)
```

Rather than carefully comparing long memory locations, we can instead use the `dplyr::changes()` function to highlights changes between two versions of a data frame. This shows us that `iris` and `iris2` are identical: both names point to the same location in memory.

```{r}
changes(iris2, iris)
```

What do you think happens if you modify a single column of `iris2`? In R 3.1.0 and above, R knows enough to only modify one column and leave the others pointing to the existing location:

```{r}
iris2$Sepal.Length <- iris2$Sepal.Length * 2
changes(iris, iris2)
```

(This was not the case prior to R 3.1.0: R created a deep copy of the entire data frame.)

dplyr is similarly smart:

```{r}
iris3 <- mutate(iris, Sepal.Length = Sepal.Length * 2)
changes(iris3, iris)
```

It's smart enough to create only one new column: all the other columns continue to point at their old locations. You might notice that the attributes have still been copied. This has little impact on performance because the attributes are usually short vectors and copying makes the internal dplyr code considerably simpler.

dplyr never makes copies unless it has to:

* `tbl_df()` and `group_by()` don't copy columns

* `select()` never copies columns, even when you rename them

* `mutate()` never copies columns, except when you modify an existing column

* `arrange()` must copy because you're changing the order of every column.
  This is an expensive operation for big data, but you can generally avoid
  it using the order argument to [window functions](window-functions.html)

* `summarise()` creates new data, but it's usually at least an order of
  magnitude smaller than the original data.

This means that dplyr lets you work with data frames with very little memory overhead.

data.table takes this idea one step further than dplyr, and provides functions that modify a data table in place. This avoids the need to copy the pointers to existing columns and attributes, and provides speed up when you have many columns. dplyr doesn't do this with data frames (although it could) because I think it's safer to keep data immutable: all dplyr data frame methods return a new data frame, even while they share as much data as possible.
